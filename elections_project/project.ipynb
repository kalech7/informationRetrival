{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entrevistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo convertido a CSV con ,: ./data/interview/Leonidas Iza.csv\n",
      "Archivo convertido a CSV con ,: ./data/interview/HenryKronfle.csv\n",
      "Archivo convertido a CSV con ,: ./data/interview/Luis Tilleria.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Archivos Excel de entrada\n",
    "archivos_excel = [\n",
    "    './data/interview/Leonidas Iza.xlsx',\n",
    "    './data/interview/HenryKronfle.xlsx',\n",
    "    './data/interview/Luis Tilleria.xlsx'\n",
    "]\n",
    "\n",
    "# Convertir cada archivo Excel a CSV con ,\n",
    "for archivo_excel in archivos_excel:\n",
    "    # Leer el archivo Excel\n",
    "    df = pd.read_excel(archivo_excel)\n",
    "    \n",
    "    # Definir el archivo CSV de salida\n",
    "    archivo_csv = archivo_excel.replace('.xlsx', '.csv')  # Reemplaza la extensi√≥n .xlsx por .csv\n",
    "    \n",
    "    # Guardar como archivo CSV con ,\n",
    "    df.to_csv(archivo_csv, index=False, sep=',')  # Usamos tabulaci√≥n como separador\n",
    "    \n",
    "    print(f\"Archivo convertido a CSV con ,: {archivo_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo procesado: ./data/interview/Leonidas_Iza_pross.csv\n",
      "‚úÖ Archivo procesado: ./data/interview/Henry_Kronfle_pross.csv\n",
      "‚úÖ Archivo procesado: ./data/interview/Luis_Tilleria_pross.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ollama  # Aseg√∫rate de tener instalada la librer√≠a con: pip install ollama\n",
    "\n",
    "# Lista de temas relevantes\n",
    "temas_relevantes = { \n",
    "    \"econom√≠a\", \"educaci√≥n\", \"salud\", \"seguridad\", \"empleo\",\n",
    "    \"infraestructura\", \"corrupci√≥n\", \"tecnolog√≠a\", \"ambiente\",\n",
    "    \"justicia\", \"transporte\", \"pol√≠tica\", \"desarrollo\", \"energ√≠a\",\n",
    "    \"derechos humanos\", \"igualdad\", \"innovaci√≥n\", \"turismo\",\n",
    "    \"agricultura\", \"cultura\", \"deporte\", \"finanzas\", \"inversi√≥n\",\n",
    "    \"vivienda\", \"servicios p√∫blicos\", \"ciencia\", \"medio ambiente\",\n",
    "    \"gobierno\", \"industria\", \"exportaciones\", \"importaciones\",\n",
    "    \"educaci√≥n superior\", \"sanidad\", \"movilidad\", \"inteligencia artificial\",\n",
    "    \"seguridad ciudadana\", \"crimen organizado\", \"democracia\", \"pobreza\",\n",
    "    \"sostenibilidad\", \"digitalizaci√≥n\", \"gesti√≥n p√∫blica\", \"comercio\",\n",
    "    \"cambio clim√°tico\", \"energ√≠as renovables\", \"transparencia\", \"ciberseguridad\",\n",
    "    \"salud p√∫blica\", \"gobernanza\", \"justicia social\", \"igualdad de g√©nero\",\n",
    "    \"emprendimiento\", \"industria 4.0\", \"desarrollo sostenible\", \"desastres naturales\",\n",
    "    \"reforestaci√≥n\", \"movilidad urbana\", \"biodiversidad\", \"educaci√≥n financiera\",\n",
    "    \"trabajo remoto\", \"accesibilidad\", \"industria alimentaria\", \"industria tecnol√≥gica\",\n",
    "    \"educaci√≥n digital\", \"cultura digital\", \"sociedad del conocimiento\", \n",
    "    \"banca digital\", \"teletrabajo\", \"inteligencia colectiva\", \"biotecnolog√≠a\",\n",
    "    \"blockchain\", \"fintech\", \"medicina personalizada\", \"econom√≠a circular\",\n",
    "    \"ciudades inteligentes\", \"protecci√≥n de datos\", \"energ√≠a solar\", \"transporte el√©ctrico\",\n",
    "    \"robotizaci√≥n\", \"computaci√≥n cu√°ntica\", \"espacio exterior\", \"protecci√≥n ambiental\",\n",
    "    \"seguridad en la nube\", \"movilidad el√©ctrica\", \"alimentos org√°nicos\", \"tecnolog√≠a educativa\",\n",
    "    \"agtech\", \"neurociencia\", \"edtech\", \"deep learning\", \"big data\", \"sistemas aut√≥nomos\",\n",
    "    \"tecnolog√≠a espacial\", \"cambio de paradigma\", \"smart grids\", \"ciudades sostenibles\", \n",
    "    \"ecoeficiencia\", \"energ√≠a e√≥lica\", \"tecnolog√≠as disruptivas\", \"energ√≠a geot√©rmica\",\n",
    "    \"nanotecnolog√≠a\", \"microbioma\", \"bioeconom√≠a\", \"ecoturismo\", \"industrias creativas\",\n",
    "    \"gobernanza digital\", \"energ√≠a limpia\", \"criptomonedas\", \"miner√≠a digital\", \"ciencias marinas\",\n",
    "    \"nanomateriales\", \"inteligencia emocional\", \"finanzas sostenibles\", \"educaci√≥n en l√≠nea\",\n",
    "    \"bio\", \"ecoinnovaci√≥n\", \"simulaci√≥n computacional\", \"agricultura urbana\", \"cultivos inteligentes\",\"IESS\"\n",
    "}\n",
    "\n",
    "# üìå Funci√≥n para extraer los temas tratados\n",
    "def extraer_temas(texto):\n",
    "    # Aseguramos que el texto no sea vac√≠o o nulo\n",
    "    if not texto or not isinstance(texto, str):\n",
    "        return \"Otros\"\n",
    "    \n",
    "    # Convertimos el texto a min√∫sculas y buscamos los temas\n",
    "    texto = texto.lower()\n",
    "    temas_detectados = [tema for tema in temas_relevantes if tema.lower() in texto]\n",
    "    \n",
    "    # Si encontramos temas, los unimos en una cadena separada por comas\n",
    "    return \", \".join(temas_detectados) if temas_detectados else \"Otros\"\n",
    "\n",
    "# üìå Funci√≥n para generar res√∫menes con Ollama\n",
    "def generar_resumen_ollama(texto):\n",
    "    prompt = f\"Resume el siguiente texto en un parrafo:\\n\\n{texto}\"\n",
    "\n",
    "    try:\n",
    "        respuesta = ollama.chat(\n",
    "            model=\"llama3.2:latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        resumen = respuesta.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "        # Eliminar saltos de l√≠nea y espacios extras\n",
    "        resumen = ' '.join(resumen.split())\n",
    "        return resumen if resumen else \"No se pudo generar el resumen\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error con Ollama: {e}\")\n",
    "        return \"Resumen no disponible\"\n",
    "\n",
    "def procesar_csv(archivo_entrada, archivo_salida):\n",
    "    df = pd.read_csv(archivo_entrada,sep=\",\")\n",
    "\n",
    "    # Verifica si la columna \"entrevista\" existe en el archivo CSV\n",
    "    if \"entrevista\" not in df.columns:\n",
    "        print(\"‚ùå La columna 'entrevista' no se encuentra en el archivo.\")\n",
    "        return\n",
    "\n",
    "    # Extraer temas tratados\n",
    "    df[\"Temas_Tratados\"] = df[\"entrevista\"].astype(str).apply(extraer_temas)\n",
    "\n",
    "    # Generar res√∫menes con Ollama\n",
    "    df[\"descripcion\"] = df[\"entrevista\"].astype(str).apply(generar_resumen_ollama)\n",
    "\n",
    "    # Guardar el archivo procesado\n",
    "    df.to_csv(archivo_salida, index=False, encoding=\"utf-8-sig\", sep=\",\")\n",
    "    print(f\"‚úÖ Archivo procesado: {archivo_salida}\")\n",
    "\n",
    "# üî• Ejecutar para m√∫ltiples archivos CSV\n",
    "procesar_csv(\"./data/interview/Leonidas Iza.csv\", \"./data/interview/Leonidas_Iza_pross.csv\")\n",
    "procesar_csv(\"./data/interview/HenryKronfle.csv\", \"./data/interview/Henry_Kronfle_pross.csv\")\n",
    "procesar_csv(\"./data/interview/Luis Tilleria.csv\", \"./data/interview/Luis_Tilleria_pross.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Andrea_Gonzalez.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": carlos_rabascall.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Daniel_Noboa.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": HenryKronfle.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Henry_Kronfle_pross.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": JimmyJairala.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": JorgeEscala.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Leonidas Iza.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Leonidas_Iza_pross.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Luis Tilleria.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Luis_Tilleria_pross.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": pedro_granja.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": victor_araus.csv\n",
      "Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": Wilson_Gomez.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\55085014.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Carpeta que contiene los archivos CSV\n",
    "directorio_csv = './data/interview'  # Cambia por la ruta de tu carpeta con archivos CSV\n",
    "\n",
    "# Definir las columnas en el orden que quieres\n",
    "columnas_ordenadas = ['ID', 'Candidato', 'Temas_Tratados', 'Descripcion', 'Entrevista']\n",
    "\n",
    "# Funci√≥n para encontrar el nombre m√°s similar a una lista de nombres\n",
    "def encontrar_columna_similar(nombre_columna, lista_columnas):\n",
    "    import difflib\n",
    "    # Encuentra la coincidencia m√°s cercana\n",
    "    coincidencias = difflib.get_close_matches(nombre_columna, lista_columnas, n=1, cutoff=0.8)\n",
    "    return coincidencias[0] if coincidencias else None\n",
    "\n",
    "# Funci√≥n para depurar un DataFrame\n",
    "def depurar_dataframe(df):\n",
    "    # Rellenar valores NaN con un valor vac√≠o o 0 dependiendo del tipo de la columna\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Si es columna de tipo texto\n",
    "            df[col].fillna('', inplace=True)\n",
    "        else:  # Si es columna num√©rica\n",
    "            df[col].fillna(0, inplace=True)\n",
    "    \n",
    "    # Verificar si todas las columnas esperadas est√°n presentes\n",
    "    for col in columnas_ordenadas:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''  # Si falta alguna columna, agregarla como vac√≠a\n",
    "    \n",
    "    # Asegurarse de que el DataFrame no est√© vac√≠o\n",
    "    if df.empty:\n",
    "        print(\"El DataFrame est√° vac√≠o, no se guardar√°.\")\n",
    "        return None\n",
    "    \n",
    "    # Asignar numeraci√≥n secuencial a la columna 'ID'\n",
    "    df['ID'] = range(1, len(df) + 1)\n",
    "    \n",
    "    # Reordenar las columnas del DataFrame\n",
    "    df = df[columnas_ordenadas]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Iterar sobre todos los archivos en la carpeta\n",
    "for archivo in os.listdir(directorio_csv):\n",
    "    if archivo.endswith('.csv'):\n",
    "        archivo_csv = os.path.join(directorio_csv, archivo)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(archivo_csv, sep=',', quoting=csv.QUOTE_MINIMAL, quotechar='\"')\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Renombrar las columnas si hay coincidencias\n",
    "        columnas_actuales = df.columns.tolist()\n",
    "        columnas_renombradas = {}\n",
    "        \n",
    "        for col in columnas_actuales:\n",
    "            columna_similar = encontrar_columna_similar(col, columnas_ordenadas)\n",
    "            if columna_similar:\n",
    "                columnas_renombradas[col] = columna_similar\n",
    "        \n",
    "        # Renombrar las columnas en el DataFrame\n",
    "        df.rename(columns=columnas_renombradas, inplace=True)\n",
    "        \n",
    "        # Depurar el DataFrame\n",
    "        df_limpio = depurar_dataframe(df)\n",
    "        \n",
    "        if df_limpio is not None:\n",
    "            # Guardar el archivo CSV con el nuevo orden de columnas y delimitador \";\"\n",
    "            df_limpio.to_csv(archivo_csv, index=False, sep=',')\n",
    "            print(f'Archivo renombrado, ordenado y con numeraci√≥n secuencial en \"ID\": {archivo}')\n",
    "        else:\n",
    "            print(f'El archivo {archivo} no se guard√≥ debido a que est√° vac√≠o o con errores.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unir entrevistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo combinado guardado como: ./data/interview/archivo_combinado.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\kale\\AppData\\Local\\Temp\\ipykernel_6128\\3395417661.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Carpeta que contiene los archivos CSV\n",
    "directorio_csv = './data/interview/'  # Cambia por la ruta de tu carpeta con archivos CSV\n",
    "\n",
    "# Definir las columnas en el orden que quieres\n",
    "columnas_ordenadas = ['ID', 'Candidato', 'Temas_Tratados', 'Descripcion', 'Entrevista']\n",
    "\n",
    "# Funci√≥n para encontrar el nombre m√°s similar a una lista de nombres\n",
    "def encontrar_columna_similar(nombre_columna, lista_columnas):\n",
    "    import difflib\n",
    "    # Encuentra la coincidencia m√°s cercana\n",
    "    coincidencias = difflib.get_close_matches(nombre_columna, lista_columnas, n=1, cutoff=0.8)\n",
    "    return coincidencias[0] if coincidencias else None\n",
    "\n",
    "# Funci√≥n para depurar un DataFrame\n",
    "def depurar_dataframe(df):\n",
    "    # Rellenar valores NaN con un valor vac√≠o o 0 dependiendo del tipo de la columna\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Si es columna de tipo texto\n",
    "            df[col].fillna('', inplace=True)\n",
    "        else:  # Si es columna num√©rica\n",
    "            df[col].fillna(0, inplace=True)\n",
    "    \n",
    "    # Verificar si todas las columnas esperadas est√°n presentes\n",
    "    for col in columnas_ordenadas:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''  # Si falta alguna columna, agregarla como vac√≠a\n",
    "    \n",
    "    # Asegurarse de que el DataFrame no est√© vac√≠o\n",
    "    if df.empty:\n",
    "        print(\"El DataFrame est√° vac√≠o, no se guardar√°.\")\n",
    "        return None\n",
    "    \n",
    "    # Reordenar las columnas del DataFrame\n",
    "    df = df[columnas_ordenadas]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Lista para almacenar todos los DataFrames\n",
    "df_final = []\n",
    "id_contador = 1  # Contador para los IDs secuenciales\n",
    "\n",
    "# Iterar sobre todos los archivos en la carpeta\n",
    "for archivo in os.listdir(directorio_csv):\n",
    "    if archivo.endswith('.csv'):\n",
    "        archivo_csv = os.path.join(directorio_csv, archivo)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(archivo_csv, sep=',', quoting=csv.QUOTE_MINIMAL, quotechar='\"')\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Renombrar las columnas si hay coincidencias\n",
    "        columnas_actuales = df.columns.tolist()\n",
    "        columnas_renombradas = {}\n",
    "        \n",
    "        for col in columnas_actuales:\n",
    "            columna_similar = encontrar_columna_similar(col, columnas_ordenadas)\n",
    "            if columna_similar:\n",
    "                columnas_renombradas[col] = columna_similar\n",
    "        \n",
    "        # Renombrar las columnas en el DataFrame\n",
    "        df.rename(columns=columnas_renombradas, inplace=True)\n",
    "        \n",
    "        # Depurar el DataFrame\n",
    "        df_limpio = depurar_dataframe(df)\n",
    "        \n",
    "        if df_limpio is not None:\n",
    "            # Asignar los IDs secuenciales antes de agregar el DataFrame al archivo final\n",
    "            df_limpio['ID'] = range(id_contador, id_contador + len(df_limpio))\n",
    "            id_contador += len(df_limpio)  # Incrementar el contador para el siguiente archivo\n",
    "            \n",
    "            # Agregar el DataFrame limpio a la lista\n",
    "            df_final.append(df_limpio)\n",
    "        else:\n",
    "            print(f'El archivo {archivo} no se guard√≥ debido a que est√° vac√≠o o con errores.')\n",
    "\n",
    "# Combinar todos los DataFrames en uno solo\n",
    "df_combinado = pd.concat(df_final, ignore_index=True)\n",
    "\n",
    "# Guardar el archivo combinado en un nuevo CSV\n",
    "archivo_combinado = './data/interview/archivo_combinado.csv'\n",
    "df_combinado.to_csv(archivo_combinado, index=False, sep=',')\n",
    "\n",
    "print(f'Archivo combinado guardado como: {archivo_combinado}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo expandido guardado como: ./data/interview/archivo_combinado_expandido.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Funci√≥n para limpiar el contenido del texto\n",
    "def clean_content(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''  # Si no es un string, devolver vac√≠o\n",
    "    \n",
    "    # Eliminar vi√±etas comunes\n",
    "    text = re.sub(r\"[\\u2022\\u25CB\\u2023\\u2219\\u2022\\u25AA\\u25B6\\u25B7\\u25C6\\u2043\\u25B8\\u25BB\\u2660\\u25FE\\u25FB]\", \"\", text)\n",
    "    text = re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "    \n",
    "    # Eliminar enumeraciones (n√∫meros seguidos de punto)\n",
    "    text = re.sub(r'^\\d+\\.', '', text)  # Al inicio de la l√≠nea\n",
    "    text = re.sub(r'\\n\\d+\\.', '\\n', text)  # En medio del texto\n",
    "    \n",
    "    # Reemplazar m√∫ltiples espacios con uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Funci√≥n para dividir el texto en oraciones por ID\n",
    "def dividir_oraciones_por_id(text, text_id):\n",
    "    delimitadores = '.'\n",
    "    oraciones = []\n",
    "    oracion_actual = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        oracion_actual += char\n",
    "        if char in delimitadores:\n",
    "            oraciones.append(oracion_actual.strip())\n",
    "            oracion_actual = \"\"\n",
    "    \n",
    "    if oracion_actual:  # Si hay algo restante\n",
    "        oraciones.append(oracion_actual.strip())\n",
    "    \n",
    "    # Crear una lista de tuplas con ID y oraciones\n",
    "    return [(text_id, i, oracion) for i, oracion in enumerate(oraciones, start=1)]\n",
    "\n",
    "# Cargar el archivo combinado\n",
    "archivo_combinado = './data/interview/archivo_combinado.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(archivo_combinado)\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: No se encontr√≥ el archivo {archivo_combinado}\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"‚ùå Error: El archivo {archivo_combinado} est√° vac√≠o.\")\n",
    "    exit()\n",
    "\n",
    "# Verificar si la columna 'ID' ya existe\n",
    "if 'ID' in df.columns:\n",
    "    df = df.sort_values(by='ID').reset_index(drop=True)  # Ordenar por ID y resetear √≠ndices\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Advertencia: La columna 'ID' no existe. Se generar√° numeraci√≥n autom√°tica.\")\n",
    "    df['ID'] = range(1, len(df) + 1)\n",
    "\n",
    "# Crear lista para almacenar las nuevas filas con oraciones separadas\n",
    "nuevas_filas = []\n",
    "\n",
    "# Procesar cada fila del dataframe\n",
    "for _, row in df.iterrows():\n",
    "    text_id = row['ID']\n",
    "    texto_limpio = clean_content(row.get('Entrevista', ''))  # Limpiar el texto antes de dividirlo\n",
    "    oraciones = dividir_oraciones_por_id(texto_limpio, text_id)  # Extraer oraciones con ID\n",
    "    \n",
    "    for id_original, id_oracion, oracion in oraciones:\n",
    "        nueva_fila = row.drop(labels=['Entrevista'], errors='ignore').to_dict()  # Evitar KeyError\n",
    "        nueva_fila['ID_Oracion'] = f\"{id_original}-{id_oracion}\"  # ID √∫nico para cada oraci√≥n\n",
    "        nueva_fila['Oracion_Entrevista'] = oracion\n",
    "        nuevas_filas.append(nueva_fila)\n",
    "\n",
    "# Convertir la lista de nuevas filas en un DataFrame\n",
    "df_expandido = pd.DataFrame(nuevas_filas)\n",
    "\n",
    "# Reajustar la columna ID para que sea secuencial\n",
    "df_expandido['ID'] = range(1, len(df_expandido) + 1)\n",
    "\n",
    "# Guardar el archivo actualizado con oraciones separadas\n",
    "archivo_expandido = './data/interview/archivo_combinado_expandido.csv'\n",
    "df_expandido.to_csv(archivo_expandido, index=False, sep=',')\n",
    "\n",
    "print(f'‚úÖ Archivo expandido guardado como: {archivo_expandido}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# columna id, partido politico,content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos agregados al archivo CSV: candidatos.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "# Directorio donde est√°n los archivos PDF\n",
    "pdf_directory = \"./data/\"\n",
    "output_csv = \"candidatos.csv\"\n",
    "\n",
    "# Lista de diccionarios espec√≠ficos a procesar\n",
    "file_parameters = [\n",
    "    {\"file_name\": \"REVOLUCI√ìN CIUDADANA - RETO _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO SOCIEDAD UNIDA M√ÅS ACCI√ìN, SUMA _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO IZQUIERDA DEMOCR√ÅTICA _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO CENTRO DEMOCR√ÅTICO _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO CONSTRUYE _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO CREO, CREANDO OPORTUNIDADES _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO AMIGO, ACCI√ìN MOVILIZADORA INDEPENDIENTE GENERANDO OPORTUNIDADES _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO PUEBLO IGUALDAD DEMOCRACIA _PID_ _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO ACCION DEMOCRATICA NACIONAL, ADN _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO SOCIEDAD PATRI√ìTICA  21 DE ENERO _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO UNIDAD POPULAR _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO SOCIALISTA ECUATORIANO _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO DEMOCRACIA S√ç _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO AVANZA _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"PARTIDO SOCIAL CRISTIANO _Plan de trabajo_.pdf\"},\n",
    "    {\"file_name\": \"MOVIMIENTO DE UNIDAD PLURINACIONAL PACHAKUTIK _Plan de trabajo_.pdf\"},\n",
    "]\n",
    "\n",
    "# Funci√≥n para obtener el √∫ltimo ID del archivo CSV\n",
    "def get_last_id(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return 1\n",
    "    df = pd.read_csv(csv_path, sep=\"|\", encoding=\"utf-8\")\n",
    "    if df.empty:\n",
    "        return 1\n",
    "    return df['ID'].iloc[-1] + 1\n",
    "\n",
    "\n",
    "# Obtener el ID inicial\n",
    "file_id = get_last_id(output_csv)\n",
    "\n",
    "# Crear una lista para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Recorrer la lista de diccionarios espec√≠ficos\n",
    "for file_param in file_parameters:\n",
    "    file_name = file_param[\"file_name\"]\n",
    "\n",
    "    # Construir la ruta completa del archivo\n",
    "    pdf_path = os.path.join(pdf_directory, file_name)\n",
    "\n",
    "    # Verificar si el archivo existe\n",
    "    if os.path.exists(pdf_path):\n",
    "        # Procesar el nombre del archivo\n",
    "        processed_name = file_name.replace(\"_Plan de trabajo_\", \"\").replace(\".pdf\", \"\")\n",
    "\n",
    "        # Agregar los datos a la lista\n",
    "        data.append([file_id, processed_name])\n",
    "        file_id += 1\n",
    "    else:\n",
    "        print(f\"Archivo no encontrado: {file_name}\")\n",
    "\n",
    "# Crear un DataFrame a partir de los datos nuevos\n",
    "df_new = pd.DataFrame(data, columns=['ID', 'Nombre'])\n",
    "\n",
    "# Verificar si el archivo CSV ya existe\n",
    "if os.path.exists(output_csv):\n",
    "    # Leer el archivo CSV existente\n",
    "    df_existing = pd.read_csv(output_csv, sep=\"|\", encoding=\"utf-8\")\n",
    "    # Concatenar los datos nuevos con los existentes\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "else:\n",
    "    df_combined = df_new\n",
    "\n",
    "# Guardar el DataFrame combinado en el archivo CSV con delimitador \";\"\n",
    "df_combined.to_csv(output_csv, sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Datos agregados al archivo CSV: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos agregados al archivo CSV: oraciones.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "# Directorio donde est√°n los archivos PDF\n",
    "pdf_directory = \"./data/\"\n",
    "output_csv = \"oraciones.csv\"\n",
    "\n",
    "# Lista de diccionarios espec√≠ficos a procesar\n",
    "file_parameters = [\n",
    "    {\"file_name\": \"REVOLUCI√ìN CIUDADANA - RETO _Plan de trabajo_.pdf\", \"exclude_pages_start\": 8},\n",
    "    {\"file_name\": \"PARTIDO SOCIEDAD UNIDA M√ÅS ACCI√ìN, SUMA _Plan de trabajo_.pdf\", \"exclude_pages_start\": 7},\n",
    "    {\"file_name\": \"PARTIDO IZQUIERDA DEMOCR√ÅTICA _Plan de trabajo_.pdf\",\"exclude_pages_start\": 5},\n",
    "    {\"file_name\": \"MOVIMIENTO CENTRO DEMOCR√ÅTICO _Plan de trabajo_.pdf\", \"exclude_pages_start\": 4},\n",
    "    {\"file_name\": \"MOVIMIENTO CONSTRUYE _Plan de trabajo_.pdf\", \"exclude_pages_start\": 4},\n",
    "    {\"file_name\": \"MOVIMIENTO CREO, CREANDO OPORTUNIDADES _Plan de trabajo_.pdf\", \"exclude_pages_start\": 4},\n",
    "    {\"file_name\": \"MOVIMIENTO AMIGO, ACCI√ìN MOVILIZADORA INDEPENDIENTE GENERANDO OPORTUNIDADES _Plan de trabajo_.pdf\", \"exclude_pages_start\": 4},\n",
    "    {\"file_name\": \"MOVIMIENTO PUEBLO IGUALDAD DEMOCRACIA _PID_ _Plan de trabajo_.pdf\", \"exclude_pages_start\": 3},\n",
    "    {\"file_name\": \"MOVIMIENTO ACCION DEMOCRATICA NACIONAL, ADN _Plan de trabajo_.pdf\", \"exclude_pages_start\": 3},\n",
    "    {\"file_name\": \"PARTIDO SOCIEDAD PATRI√ìTICA  21 DE ENERO _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"PARTIDO UNIDAD POPULAR _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"PARTIDO SOCIALISTA ECUATORIANO _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"MOVIMIENTO DEMOCRACIA S√ç _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"PARTIDO AVANZA _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"PARTIDO SOCIAL CRISTIANO _Plan de trabajo_.pdf\", \"exclude_pages_start\": 2},\n",
    "    {\"file_name\": \"MOVIMIENTO DE UNIDAD PLURINACIONAL PACHAKUTIK _Plan de trabajo_.pdf\", \"exclude_pages_start\": 1}\n",
    "]\n",
    "\n",
    "# Funci√≥n para obtener el √∫ltimo ID del archivo CSV\n",
    "def get_last_id(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return 1\n",
    "    df = pd.read_csv(csv_path, sep=\"|\", encoding=\"utf-8\")\n",
    "    if df.empty:\n",
    "        return 1\n",
    "    return df['ID'].iloc[-1] + 1\n",
    "\n",
    "# Funci√≥n para extraer texto del PDF excluyendo las primeras y √∫ltimas p√°ginas\n",
    "def extract_text_excluding_pages(pdf_path, exclude_pages_start, exclude_pages_end=1):\n",
    "    extracted_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(exclude_pages_start, len(pdf.pages) - exclude_pages_end):\n",
    "            page_text = pdf.pages[i].extract_text()\n",
    "            if page_text:\n",
    "                extracted_text += page_text + \"\\n\"\n",
    "    return extracted_text.strip()\n",
    "\n",
    "# Funci√≥n para limpiar el contenido del texto\n",
    "def clean_content(text):\n",
    "    # Eliminar vi√±etas comunes\n",
    "    text = re.sub(r\"[\\u2022\\u25CB\\u2023\\u2219\\u2022\\u25AA\\u25B6\\u25B7\\u25C6\\u2043\\u25B8\\u25BB\\u2660\\u25FE\\u25FB]\", \"\", text)\n",
    "    text = re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "    # Eliminar enumeraciones (n√∫meros seguidos de punto)\n",
    "    text = re.sub(r'^\\d+\\.', '', text)  # Al inicio de la l√≠nea\n",
    "    text = re.sub(r'\\n\\d+\\.', '\\n', text)  # En medio del texto\n",
    "    \n",
    "    # Reemplazar m√∫ltiples espacios con uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Funci√≥n para dividir el texto en oraciones\n",
    "def dividir_oraciones_por_id(text, text_id):\n",
    "    delimitadores = '.'\n",
    "    oraciones = []\n",
    "    oracion_actual = \"\"\n",
    "    for char in text:\n",
    "        oracion_actual += char\n",
    "        if char in delimitadores:\n",
    "            oraciones.append(oracion_actual.strip())\n",
    "            oracion_actual = \"\"\n",
    "    if oracion_actual:  # Si hay algo restante\n",
    "        oraciones.append(oracion_actual.strip())\n",
    "    \n",
    "    # Crear una lista de tuplas con id y oraciones\n",
    "    return [(text_id, i, oracion) for i, oracion in enumerate(oraciones, start=1)]\n",
    "\n",
    "# Obtener el ID inicial\n",
    "file_id = get_last_id(output_csv)\n",
    "\n",
    "# Crear una lista para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Recorrer la lista de diccionarios espec√≠ficos\n",
    "for file_param in file_parameters:\n",
    "    file_name = file_param[\"file_name\"]\n",
    "    exclude_pages_start = file_param[\"exclude_pages_start\"]\n",
    "\n",
    "    # Construir la ruta completa del archivo\n",
    "    pdf_path = os.path.join(pdf_directory, file_name)\n",
    "\n",
    "    # Verificar si el archivo existe\n",
    "    if os.path.exists(pdf_path):\n",
    "        # Procesar el nombre del archivo\n",
    "        processed_name = file_name.replace(\"_Plan de trabajo_\", \"\").replace(\".pdf\", \"\")\n",
    "\n",
    "        # Extraer el contenido del PDF\n",
    "        content = extract_text_excluding_pages(pdf_path, exclude_pages_start=exclude_pages_start)\n",
    "\n",
    "        # Limpiar el contenido extra√≠do\n",
    "        cleaned_content = clean_content(content)\n",
    "\n",
    "        # Dividir el contenido en oraciones\n",
    "        oraciones = dividir_oraciones_por_id(cleaned_content, file_id)\n",
    "\n",
    "        # Agregar las oraciones a la lista de datos\n",
    "        data.extend(oraciones)\n",
    "\n",
    "        # Incrementar el ID\n",
    "        file_id += 1\n",
    "    else:\n",
    "        print(f\"Archivo no encontrado: {file_name}\")\n",
    "\n",
    "# Crear un DataFrame a partir de las oraciones\n",
    "df_oraciones = pd.DataFrame(data, columns=['ID', 'Oracion_ID', 'Oracion'])\n",
    "\n",
    "# Verificar si el archivo CSV ya existe\n",
    "if os.path.exists(output_csv):\n",
    "    # Leer el archivo CSV existente\n",
    "    df_existing = pd.read_csv(output_csv, sep=\"|\", encoding=\"utf-8\")\n",
    "    # Concatenar los datos nuevos con los existentes\n",
    "    df_combined = pd.concat([df_existing, df_oraciones], ignore_index=True)\n",
    "else:\n",
    "    df_combined = df_oraciones\n",
    "\n",
    "# Guardar el DataFrame combinado en el archivo CSV con delimitador \";\"\n",
    "df_combined.to_csv(output_csv, sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Datos agregados al archivo CSV: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alech/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIDO UNIDAD POPULAR _Plan de trabajo_.pdf procesado (ID 11)\n",
      "MOVIMIENTO DEMOCRACIA S√ç _Plan de trabajo_.pdf procesado (ID 13)\n",
      "PARTIDO SOCIAL CRISTIANO _Plan de trabajo_.pdf procesado (ID 15)\n",
      "\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import csv\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Descargar el recurso necesario para tokenizar oraciones\n",
    "nltk.download('punkt')\n",
    "\n",
    "csv.field_size_limit(1000000)\n",
    "\n",
    "# Configuraci√≥n global\n",
    "pdf_directory = \"./data/\"\n",
    "csv_file = \"oraciones.csv\"\n",
    "columns = ['ID', 'Nombre', 'Contenido']\n",
    "\n",
    "# Configurar Tesseract para Fedora\n",
    "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
    "\n",
    "def procesar_pdf(ruta_pdf, id_asignado, nombre_doc):\n",
    "    try:\n",
    "        # Convertir PDF a im√°genes\n",
    "        images = convert_from_path(ruta_pdf, dpi=300)\n",
    "        \n",
    "        # Extraer y limpiar texto\n",
    "        contenido = \" \".join(\n",
    "            [pytesseract.image_to_string(img, lang='spa').strip().replace('\\n', ' ') \n",
    "             for img in images]\n",
    "        )\n",
    "        \n",
    "        # Tokenizar el texto en oraciones\n",
    "        oraciones = sent_tokenize(contenido, language='spanish')\n",
    "        \n",
    "        # Asignar ID √∫nico a cada oraci√≥n\n",
    "        oraciones_ids = []\n",
    "        oraciones_texto = []\n",
    "        \n",
    "        for i, oracion in enumerate(oraciones):\n",
    "            oraciones_ids.append(f\"{id_asignado}_{i}\")  # ID √∫nico para cada oraci√≥n\n",
    "            oraciones_texto.append(oracion)  # Texto de la oraci√≥n\n",
    "        \n",
    "        # Crear DataFrame con solo los campos requeridos\n",
    "        data = {\n",
    "            'ID': [id_asignado] * len(oraciones),\n",
    "            'Oracion_ID': oraciones_ids,\n",
    "            'Oracion': oraciones_texto\n",
    "        }\n",
    "        df_oraciones = pd.DataFrame(data, columns=['ID', 'Oracion_ID', 'Oracion'])\n",
    "        \n",
    "        # Escribir el DataFrame al CSV (o concatenar al existente)\n",
    "        if os.path.exists(csv_file):\n",
    "            df_oraciones.to_csv(csv_file, mode='a', header=False, index=False, sep=';')\n",
    "        else:\n",
    "            df_oraciones.to_csv(csv_file, mode='w', header=True, index=False, sep=';')\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {ruta_pdf}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Mapeo de archivos a IDs y nombres\n",
    "documentos = {\n",
    "    \"PARTIDO UNIDAD POPULAR _Plan de trabajo_.pdf\": {\"id\": 11, \"nombre\": \"PARTIDO UNIDAD POPULAR\"},\n",
    "    \"MOVIMIENTO DEMOCRACIA S√ç _Plan de trabajo_.pdf\": {\"id\": 13, \"nombre\": \"MOVIMIENTO DEMOCRACIA S√ç\"},\n",
    "    \"PARTIDO SOCIAL CRISTIANO _Plan de trabajo_.pdf\": {\"id\": 15, \"nombre\": \"PARTIDO SOCIAL CRISTIANO\"}   \n",
    "}\n",
    "\n",
    "# Procesar todos los documentos\n",
    "for archivo, datos in documentos.items():\n",
    "    ruta_completa = os.path.join(pdf_directory, archivo)\n",
    "    if os.path.exists(ruta_completa):\n",
    "        if procesar_pdf(ruta_completa, datos['id'], datos['nombre']):\n",
    "            print(f\"{archivo} procesado (ID {datos['id']})\")\n",
    "    else:\n",
    "        print(f\"Archivo no encontrado: {ruta_completa}\")\n",
    "\n",
    "print(\"\\nProceso completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# limpiar la columna oracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo oraciones.csv procesado, limpiado y ordenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Funci√≥n para limpiar el contenido del texto\n",
    "def clean_content(text):\n",
    "    text = text.lower()\n",
    "    # Eliminar vi√±etas comunes\n",
    "    text = re.sub(r\"[\\u2022\\u25CB\\u2023\\u2219\\u2022\\u25AA\\u25B6\\u25B7\\u25C6\\u2043\\u25B8\\u25BB\\u2660\\u25FE\\u25FB]\", \"\", text)\n",
    "    \n",
    "    # Eliminar (cid:...) - Referencias CID\n",
    "    text = re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "    \n",
    "    # Eliminar enumeraciones (n√∫meros seguidos de punto)\n",
    "    text = re.sub(r'^\\d+\\.', '', text)  # Al inicio de la l√≠nea\n",
    "    text = re.sub(r'\\n\\d+\\.', '\\n', text)  # En medio del texto\n",
    "\n",
    "    # Eliminar la enumeraci√≥n de p√°gina (ejemplo: 'P√°gina 1', 'p√°g. 2', etc.)\n",
    "    text = re.sub(r'P√°gina \\d+', '', text)\n",
    "    text = re.sub(r'p√°g\\.\\s*\\d+', '', text)\n",
    "    text = re.sub(r'pag\\.\\s*\\d+', '', text)\n",
    "    text = re.sub(r'Page \\d+', '', text)\n",
    "    text = re.sub(r'page \\d+', '', text)\n",
    "\n",
    "    # Eliminar caracteres especiales no alfab√©ticos ni num√©ricos (como @, #, $, etc.)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Reemplazar m√∫ltiples espacios con uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Leer el archivo CSV, limpiar el contenido de la columna \"Oracion\", ordenar por ID y guardar\n",
    "def limpiar_y_guardar_csv(csv_file):\n",
    "    try:\n",
    "        filas_existentes = []\n",
    "        \n",
    "        # Leer las filas existentes desde el CSV\n",
    "        if os.path.exists(csv_file):\n",
    "            with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "                reader = csv.DictReader(f, delimiter=';')\n",
    "                for row in reader:\n",
    "                    # Limpiar el contenido de la columna \"Oracion\"\n",
    "                    row['Oracion'] = clean_content(row['Oracion'])\n",
    "                    \n",
    "                    # Verificar si la columna \"Oracion\" no est√° vac√≠a\n",
    "                    if row['Oracion']:  \n",
    "                        filas_existentes.append(row)\n",
    "        \n",
    "        # Ordenar las filas por ID (conversi√≥n a int para evitar errores de ordenaci√≥n)\n",
    "        filas_existentes.sort(key=lambda x: int(x['ID']))\n",
    "\n",
    "        # Escribir las filas modificadas en el archivo CSV\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['ID', 'Oracion_ID', 'Oracion'], delimiter=';')\n",
    "            writer.writeheader()\n",
    "            writer.writerows(filas_existentes)\n",
    "        \n",
    "        print(f\"Archivo {csv_file} procesado, limpiado y ordenado correctamente.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando el archivo CSV: {str(e)}\")\n",
    "\n",
    "# Llamar a la funci√≥n\n",
    "limpiar_y_guardar_csv('oraciones.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV actualizado con √©xito. Se agregaron las columnas 'Temas Clave'.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Cargar modelo de lenguaje en espa√±ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Cargar el CSV con las oraciones\n",
    "df = pd.read_csv(\"oraciones.csv\", sep=\";\")\n",
    "\n",
    "# Lista ampliada de temas clave\n",
    "temas_relevantes = {\n",
    "    \"econom√≠a\", \"educaci√≥n\", \"salud\", \"seguridad\", \"empleo\",\n",
    "    \"infraestructura\", \"corrupci√≥n\", \"tecnolog√≠a\", \"ambiente\",\n",
    "    \"justicia\", \"transporte\", \"pol√≠tica\", \"desarrollo\", \"energ√≠a\",\n",
    "    \"derechos humanos\", \"igualdad\", \"innovaci√≥n\", \"turismo\",\n",
    "    \"agricultura\", \"cultura\", \"deporte\", \"finanzas\", \"inversi√≥n\",\n",
    "    \"vivienda\", \"servicios p√∫blicos\", \"ciencia\", \"medio ambiente\",\n",
    "    \"gobierno\", \"industria\", \"exportaciones\", \"importaciones\",\n",
    "    \"educaci√≥n superior\", \"sanidad\", \"movilidad\", \"inteligencia artificial\",\n",
    "    \"seguridad ciudadana\", \"crimen organizado\", \"democracia\", \"pobreza\",\n",
    "    \"sostenibilidad\", \"digitalizaci√≥n\", \"gesti√≥n p√∫blica\", \"comercio\",\n",
    "    \"cambio clim√°tico\", \"energ√≠as renovables\", \"transparencia\", \"ciberseguridad\",\n",
    "    \"salud p√∫blica\", \"gobernanza\", \"justicia social\", \"igualdad de g√©nero\",\n",
    "    \"emprendimiento\", \"industria 4.0\", \"desarrollo sostenible\", \"desastres naturales\",\n",
    "    \"reforestaci√≥n\", \"movilidad urbana\", \"biodiversidad\", \"educaci√≥n financiera\",\n",
    "    \"trabajo remoto\", \"accesibilidad\", \"industria alimentaria\", \"industria tecnol√≥gica\",\n",
    "    \"educaci√≥n digital\", \"cultura digital\", \"sociedad del conocimiento\", \n",
    "    \"banca digital\", \"teletrabajo\", \"inteligencia colectiva\", \"biotecnolog√≠a\",\n",
    "    \"blockchain\", \"fintech\", \"medicina personalizada\", \"econom√≠a circular\",\n",
    "    \"ciudades inteligentes\", \"protecci√≥n de datos\", \"energ√≠a solar\", \"transporte el√©ctrico\",\n",
    "    \"robotizaci√≥n\", \"computaci√≥n cu√°ntica\", \"espacio exterior\", \"protecci√≥n ambiental\",\n",
    "    \"seguridad en la nube\", \"movilidad el√©ctrica\", \"alimentos org√°nicos\", \"tecnolog√≠a educativa\",\n",
    "    \"agtech\", \"neurociencia\", \"edtech\", \"deep learning\", \"big data\", \"sistemas aut√≥nomos\",\n",
    "    \"tecnolog√≠a espacial\", \"cambio de paradigma\", \"smart grids\", \"ciudades sostenibles\", \n",
    "    \"ecoeficiencia\", \"energ√≠a e√≥lica\", \"tecnolog√≠as disruptivas\", \"energ√≠a geot√©rmica\",\n",
    "    \"nanotecnolog√≠a\", \"microbioma\", \"bioeconom√≠a\", \"ecoturismo\", \"industrias creativas\",\n",
    "    \"gobernanza digital\", \"energ√≠a limpia\", \"criptomonedas\", \"miner√≠a digital\", \"ciencias marinas\",\n",
    "    \"nanomateriales\", \"inteligencia emocional\", \"finanzas sostenibles\", \"educaci√≥n en l√≠nea\",\n",
    "    \"biomimicry\", \"ecoinnovaci√≥n\", \"simulaci√≥n computacional\", \"agricultura urbana\", \"cultivos inteligentes\"\n",
    "}\n",
    "\n",
    "# Funci√≥n para extraer solo los temas clave\n",
    "def extraer_temas_clave(texto):\n",
    "    if pd.isna(texto):  # Manejar valores nulos\n",
    "        return \"\"\n",
    "\n",
    "    oraciones = sent_tokenize(texto, language=\"spanish\")  # Dividir en oraciones\n",
    "    temas_detectados = set()\n",
    "\n",
    "    for oracion in oraciones:\n",
    "        # Identificar temas clave dentro de la oraci√≥n\n",
    "        temas_detectados.update({tema for tema in temas_relevantes if tema in oracion.lower()})\n",
    "\n",
    "    # Retornar los temas clave detectados como una cadena separada por coma\n",
    "    return \", \".join(temas_detectados)\n",
    "\n",
    "# Aplicar la extracci√≥n de temas clave en cada fila del DataFrame\n",
    "df[\"Temas Clave\"] = df[\"Oracion\"].apply(extraer_temas_clave)\n",
    "\n",
    "# Guardar el nuevo CSV con la nueva columna 'Temas Clave' sin eliminar datos anteriores\n",
    "df.to_csv(\"oraciones_actualizado.csv\", index=False, sep=\";\")\n",
    "\n",
    "print(\" CSV actualizado con √©xito. Se agregaron las columnas 'Temas Clave'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words, tokenizar,lemmatizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado y guardado correctamente en: oraciones_procesadas.csv\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar recursos necesarios\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Inicializar el lematizador de SpaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Obtener las stopwords en espa√±ol de NLTK\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Funci√≥n para lematizar y eliminar stopwords\n",
    "def lematizar_y_eliminar_stopwords(texto):\n",
    "    doc = nlp(texto)\n",
    "    # Lematizar y eliminar stopwords\n",
    "    return ' '.join([token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in stop_words])\n",
    "\n",
    "# Limpiar contenido eliminando puntuaciones y n√∫meros\n",
    "def clean_content(texto):\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Eliminar puntuaciones\n",
    "    texto = re.sub(r'\\d+', '', texto)      # Eliminar n√∫meros\n",
    "    return texto.lower()\n",
    "\n",
    "# Funci√≥n para procesar el CSV\n",
    "def limpiar_y_guardar_csv(csv_file, output_csv):\n",
    "    try:\n",
    "        filas_existentes = []\n",
    "        \n",
    "        # Leer las filas existentes desde el CSV\n",
    "        if os.path.exists(csv_file):\n",
    "            with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "                reader = csv.DictReader(f, delimiter=';')\n",
    "                for row in reader:\n",
    "                    # Limpiar el contenido de la columna \"Oracion\"\n",
    "                    if 'Oracion' in row:\n",
    "                        row['Oracion'] = clean_content(row['Oracion'])\n",
    "                        # Procesar el contenido: lematizar y eliminar stopwords\n",
    "                        row['Oracion'] = lematizar_y_eliminar_stopwords(row['Oracion'])\n",
    "                    \n",
    "                    # Verificar si la columna \"Oracion\" no est√° vac√≠a\n",
    "                    if row['Oracion']:  # Si no est√° vac√≠o o solo contiene espacios\n",
    "                        filas_existentes.append(row)\n",
    "        \n",
    "        # Escribir las filas modificadas en el archivo CSV\n",
    "        with open(output_csv, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['ID', 'Oracion_ID', 'Oracion', 'Temas Clave'], delimiter=';')\n",
    "            writer.writeheader()\n",
    "            writer.writerows(filas_existentes)\n",
    "        \n",
    "        print(f\"Archivo procesado y guardado correctamente en: {output_csv}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando el archivo CSV: {str(e)}\")\n",
    "\n",
    "# Llamar a la funci√≥n\n",
    "input_csv = 'oraciones_actualizado.csv'\n",
    "output_csv = 'oraciones_procesadas.csv'\n",
    "limpiar_y_guardar_csv(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo combinado guardado como 'oraciones_procesadas_completo.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos CSV asegurando el delimitador correcto\n",
    "df_oraciones = pd.read_csv('oraciones_procesadas.csv', delimiter=';')\n",
    "df_candidatos = pd.read_csv('candidatos.csv', delimiter=';')\n",
    "\n",
    "# Limpiar la columna 'ID' eliminando espacios y asegurando que solo contenga n√∫meros\n",
    "df_oraciones['ID'] = df_oraciones['ID'].astype(str).str.extract('(\\d+)').astype(float).astype('Int64')\n",
    "df_candidatos['ID'] = df_candidatos['ID'].astype(str).str.extract('(\\d+)').astype(float).astype('Int64')\n",
    "\n",
    "# Realizar la fusi√≥n de datos usando 'ID' como clave\n",
    "df_completo = df_oraciones.merge(df_candidatos, on='ID', how='left')\n",
    "\n",
    "# Guardar el nuevo CSV con los datos combinados\n",
    "df_completo.to_csv('oraciones_procesadas_completo.csv', sep=';', index=False)\n",
    "\n",
    "print(\"Archivo combinado guardado como 'oraciones_procesadas_completo.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enbeddings Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df962099739240fa91048bf43a4bbb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings y FAISS guardados exitosamente.\n",
      "{'ID': 4, 'Oracion_ID': '993', 'Oracion': 'eficiencia energ√©tico implementar pol√≠tica eficiencia energ√©tico sector clave industria transporte construcci√≥n promover uso tecnolog√≠a reducir consumo energ√≠a', 'Temas Clave': 'energ√≠a, transporte, ciencia, tecnolog√≠a, pol√≠tica, industria', 'Partido': 'MOVIMIENTO CENTRO DEMOCR√ÅTICO', 'CandidatoPresidente': 'JIMMY JAIRALA VALLAZZA', 'CandidatoVicePresidente': 'LUCIA VALLECILLA SUAREZ', 'ListaPolitica': '1', 'Distancia': 0.33702278}\n",
      "{'ID': 14, 'Oracion_ID': '811', 'Oracion': 'adem√°s realizar campa√±a nacional eficiencia ahorro energ√©tico √©nfasis sector comercial residencial industrial institucional', 'Temas Clave': 'industria, ciencia', 'Partido': 'PARTIDO AVANZA', 'CandidatoPresidente': 'LUIS FELIPE TILLERIA', 'CandidatoVicePresidente': 'KARLA PAULINA ROSERO', 'ListaPolitica': '8', 'Distancia': 0.38165388}\n",
      "{'ID': 14, 'Oracion_ID': '827', 'Oracion': 'campa√±a nacional eficiencia ahorro energ√©tico promover pr√°ctica eficiencia ahorro energ√©tico sector', 'Temas Clave': 'ciencia', 'Partido': 'PARTIDO AVANZA', 'CandidatoPresidente': 'LUIS FELIPE TILLERIA', 'CandidatoVicePresidente': 'KARLA PAULINA ROSERO', 'ListaPolitica': '8', 'Distancia': 0.4163392}\n",
      "{'ID': 8, 'Oracion_ID': '433', 'Oracion': 'impulso inversi√≥n privado gobierno deber crear entorno atractivo inversi√≥n privado sector energ√©tico', 'Temas Clave': 'gobierno, inversi√≥n', 'Partido': 'MOVIMIENTO PUEBLO IGUALDAD DEMOCRACIA _PID', 'CandidatoPresidente': 'VICTOR ARAUS', 'CandidatoVicePresidente': 'CRISTINA CARRERA', 'ListaPolitica': '4', 'Distancia': 0.42793632}\n",
      "{'ID': 1, 'Oracion_ID': '533', 'Oracion': 'intervenir vivienda promover eficiencia energ√©tico', 'Temas Clave': 'vivienda, ciencia', 'Partido': 'REVOLUCI√ìN CIUDADANA - RETO', 'CandidatoPresidente': 'LUISA GONZALEZ', 'CandidatoVicePresidente': 'DIEGO BORJA', 'ListaPolitica': '5-33', 'Distancia': 0.42992368}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Verificar si hay GPU disponible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Cargar los archivos CSV\n",
    "df = pd.read_csv('oraciones_procesadas_completo.csv', delimiter=';')\n",
    "\n",
    "\n",
    "# Inicializar el modelo BERT y moverlo a GPU si est√° disponible\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Crear embeddings para todas las oraciones\n",
    "embeddings = model.encode(df['Oracion'].tolist(), show_progress_bar=True, device=device)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Crear un √≠ndice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Guardar los embeddings e √≠ndice FAISS\n",
    "np.save('embeddings.npy', embeddings)\n",
    "faiss.write_index(index, 'faiss_index.index')\n",
    "\n",
    "# Guardar datos procesados en un archivo pickle\n",
    "with open('sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(df.to_dict(orient='records'), f)\n",
    "\n",
    "print(\"Embeddings y FAISS guardados exitosamente.\")\n",
    "\n",
    "# Cargar spaCy para espa√±ol\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower(), language='spanish')\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "def query_faiss(query, top_k=5):\n",
    "    cleaned_query = preprocess_text(query)\n",
    "    query_embedding = model.encode([cleaned_query], device=device).astype('float32')\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "    \n",
    "    with open('sentences.pkl', 'rb') as f:\n",
    "        sentences = pickle.load(f)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        result = sentences[I[0][i]]\n",
    "        results.append({\n",
    "            'ID': result['ID'],\n",
    "            'Oracion_ID':result['Oracion_ID'],\n",
    "            'Oracion': result['Oracion'],\n",
    "            'Temas Clave': result['Temas Clave'],\n",
    "            'Partido': result['Partido'],\n",
    "            'CandidatoPresidente': result['CandidatoPresidente'],\n",
    "            'CandidatoVicePresidente': result['CandidatoVicePresidente'],\n",
    "            'ListaPolitica': result['ListaPolitica'],\n",
    "            'Distancia': D[0][i]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Ejemplo de uso\n",
    "query = \"¬øC√≥mo mejorar la eficiencia energ√©tica en la industria?\"\n",
    "results = query_faiss(query)\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto preprocesado: que propone daniel noboa para el fortalecimiento economico?\n",
      "Consulta procesada: proponer daniel noboa fortalecimiento economico\n",
      "Bas√°ndome en las declaraciones proporcionadas, se puede resumir que el tema principal de estas discursos y manifestaciones pol√≠ticas es la promoci√≥n de pol√≠ticas y acciones que benefician al pa√≠s Ecuador, priorizando la soberan√≠a nacional, la defensa del medio ambiente, la sostenibilidad econ√≥mica y social, la seguridad ciudadana y la protecci√≥n de los derechos humanos.\n",
      "\n",
      "Muchos de los partidos pol√≠ticos mencionados en estas declaraciones, como Movimiento Creo, Movimiento Construye, Partido Sociedad Patri√≥tica 21 de Enero, Partido Sociedad Unida M√°s Acci√≥n, Movimiento Amigo y Movimiento Centro Democr√°tico, enfatizan la importancia de:\n",
      "\n",
      "1. **Desarrollo sostenible**: Promover pol√≠ticas que equilibren el crecimiento econ√≥mico con la protecci√≥n ambiental y la conservaci√≥n de los recursos naturales.\n",
      "2. **Soberan√≠a nacional**: Priorizar la independencia y autonom√≠a del pa√≠s en sus relaciones internacionales, especialmente en la integraci√≥n regional y en la cooperaci√≥n internacional.\n",
      "3. **Seguridad ciudadana**: Asegurar la seguridad y la estabilidad social, protegiendo los derechos humanos y promoviendo la justicia social.\n",
      "4. **Econom√≠a equitativa**: Propiciar pol√≠ticas econ√≥micas que favorezcan a la poblaci√≥n en general, reduciendo la brecha entre riqueza y pobreza.\n",
      "5. **Desarrollo urbano y vial**: Mejorar el estado del transporte p√∫blico y la infraestructura urbana para facilitar el acceso a servicios b√°sicos y promover un crecimiento econ√≥mico sostenible.\n",
      "\n",
      "En general, estos discursos reflejan una visi√≥n de desarrollo social y econ√≥mico equilibrado, que priorice el bienestar de los ciudadanos y la protecci√≥n del medio ambiente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import nltk\n",
    "import spacy\n",
    "import ollama  # Importar la librer√≠a para usar Ollama\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Verificar si hay GPU disponible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Cargar el archivo CSV con las oraciones procesadas\n",
    "df = pd.read_csv('oraciones_procesadas_completo.csv', delimiter=';')\n",
    "\n",
    "# Cargar el archivo CSV con los datos de los partidos y candidatos\n",
    "\n",
    "candidatos_df = pd.read_csv('candidatos.csv', delimiter=';')  # Aseg√∫rate de que el archivo correcto est√© aqu√≠\n",
    "\n",
    "# Inicializar el modelo BERT preentrenado y moverlo a la GPU si est√° disponible\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1', device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar el √≠ndice FAISS previamente guardado\n",
    "index = faiss.read_index('faiss_index.index')\n",
    "\n",
    "# Cargar los datos de oraciones\n",
    "with open('sentences.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "# Cargar el modelo de spaCy para lematizaci√≥n en espa√±ol\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Funci√≥n para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    print(f\"Texto preprocesado: {text}\")\n",
    "    tokens = word_tokenize(text.lower(), language='spanish')\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Funci√≥n para obtener la oraci√≥n original sin procesar y sus datos adicionales\n",
    "def get_oracion_data_by_id(oracion_id):\n",
    "    oracion_row = df[df['Oracion_ID'] == oracion_id]\n",
    "    if not oracion_row.empty:\n",
    "        oracion = oracion_row.iloc[0]['Oracion']\n",
    "        temas_clave = oracion_row.iloc[0]['Temas Clave']\n",
    "        return oracion, temas_clave\n",
    "    return None, None\n",
    "\n",
    "def get_partido_data_by_id(id):\n",
    "    candidato_row = candidatos_df[candidatos_df['ID'] == id]  # Buscamos usando el 'ID'\n",
    "    if not candidato_row.empty:\n",
    "        partido = candidato_row.iloc[0]['Partido']\n",
    "        candidato_presidente = candidato_row.iloc[0]['CandidatoPresidente']\n",
    "        candidato_vicepresidente = candidato_row.iloc[0]['CandidatoVicePresidente']\n",
    "        lista_politica = candidato_row.iloc[0]['ListaPolitica']\n",
    "        return partido, candidato_presidente, candidato_vicepresidente, lista_politica\n",
    "    return None, None, None, None\n",
    "\n",
    "def query_faiss_ollama(query, top_k=50):  \n",
    "    # Preprocesar la consulta\n",
    "    cleaned_query = preprocess_text(query)\n",
    "    # Mostrar el tama√±o de la consulta procesada\n",
    "    print(f\"Consulta procesada: {cleaned_query}\")\n",
    "    # Generar el embedding para la consulta\n",
    "    query_embedding = model.encode([cleaned_query], device=device).astype('float32')\n",
    "    # Realizar la b√∫squeda en el √≠ndice FAISS\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "    # Procesar los resultados\n",
    "    resultados = []\n",
    "    for i in range(top_k):\n",
    "        # Obtener el ID de la oraci√≥n correspondiente\n",
    "        oracion_id = sentences[I[0][i]]['Oracion_ID']\n",
    "\n",
    "        id= sentences[I[0][i]]['ID']\n",
    "        # Buscar la oraci√≥n original y sus temas clave usando Oracion_ID\n",
    "        oracion_original, temas_clave = get_oracion_data_by_id(oracion_id)\n",
    "\n",
    "        # Buscar los datos del partido usando el ID del candidato\n",
    "        partido, candidato_presidente, candidato_vicepresidente, lista_politica = get_partido_data_by_id(id)\n",
    "\n",
    "        if oracion_original:  # Si se encuentra la oraci√≥n original\n",
    "            resultado = (\n",
    "                f\"Oraci√≥n: {oracion_original}, \"\n",
    "                f\"Temas Clave: {temas_clave}, \"\n",
    "                f\"Partido: {partido}, \"\n",
    "                f\"Presidente: {candidato_presidente}, \"\n",
    "                f\"Vicepresidente: {candidato_vicepresidente}, \"\n",
    "                f\"Lista Pol√≠tica: {lista_politica}\"\n",
    "            )\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "    # Verificar si hemos obtenido resultados\n",
    "    if not resultados:\n",
    "        return \"No se encontraron oraciones relevantes para la consulta.\"\n",
    "\n",
    "    # Construir el prompt para Ollama con las oraciones obtenidas\n",
    "    prompt = f\"quiero que menciones los nombres de los Presidente,Vicepresidente,Lista Pol√≠tica y el partido de lo que he encontrado clasificalo:\\n\\n\" + \"\\n\".join(resultados) + \"\\n\\nGenera un resumen basado en estas declaraciones, expl√≠calo.\"\n",
    "\n",
    "    # Generar la respuesta con Ollama\n",
    "    respuesta = ollama.chat(model='llama3.2:latest', messages=[{'role': 'user', 'content': prompt}])\n",
    "\n",
    "    return respuesta['message']['content']\n",
    "\n",
    "# Ejemplo de consulta para verificar el funcionamiento\n",
    "query = \"que propone daniel noboa para el fortalecimiento economico?\"\n",
    "respuesta = query_faiss_ollama(query)\n",
    "print(respuesta)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
